# Copy to deploy/.env.gpu and adjust for your GPU host

# Neo4j
NEO4J_PASSWORD=password

# Optional: if you expose K8S Redis to the GPU host, set REDIS_URL to that address.
# Otherwise run local redis with:
#   docker compose -f deploy/docker-compose.gpu.yaml --profile local-redis up -d
REDIS_URL=redis://redis:6379/0

# Ollama on the GPU host (or elsewhere)
OLLAMA_URL=http://host.docker.internal:11434
OLLAMA_MODEL=llama3.2:3b

# Memory worker
MEMORY_UPDATE_STREAM=cognitia:memory_updates
MEMORY_CONSUMER_GROUP=memory-worker
MEMORY_CONSUMER_NAME=gpu-memory-worker
MEMORY_SERVICE_URL=http://memory:8000

# Orchestrator memory retrieval
MEMORY_RETRIEVE_LIMIT=8
MEMORY_CONTEXT_MAX_CHARS=4000

# Ports (optional overrides)
ORCHESTRATOR_PORT=8080
MEMORY_PORT=8002
MEMORY_WORKER_PORT=8005
STT_PORT=8003
TTS_PORT=8004
QDRANT_PORT=6333
NEO4J_HTTP_PORT=7474
NEO4J_BOLT_PORT=7687
