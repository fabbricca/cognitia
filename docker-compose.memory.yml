version: '3.8'

services:
  # Memory Add-on API
  memory-addon:
    build:
      context: ./src/cognitia/memory
      dockerfile: Dockerfile
    container_name: cognitia-memory-addon
    ports:
      - "8002:8000"
    environment:
      NEO4J_URI: bolt://neo4j:7687
      NEO4J_USER: neo4j
      NEO4J_PASSWORD: ${NEO4J_PASSWORD:-memorypass}
      QDRANT_URL: http://qdrant:6333
      QDRANT_COLLECTION: cognitia_episodes
      OLLAMA_URL: http://172.17.0.1:11434
      OLLAMA_MODEL: llama3.2:latest
      EMBEDDING_MODEL: sentence-transformers/all-MiniLM-L6-v2
      PERSONA_STORAGE_DIR: /app/personas
      OPENAI_API_KEY: ollama-placeholder  # Placeholder for Ollama (doesn't validate)
    depends_on:
      - neo4j
      - qdrant
    volumes:
      - ./personas:/app/personas
    restart: unless-stopped
    networks:
      - memory-network

  # Neo4j for Graphiti
  neo4j:
    image: neo4j:5.26-community
    container_name: cognitia-neo4j
    ports:
      - "7474:7474"  # Web UI
      - "7687:7687"  # Bolt protocol
    environment:
      NEO4J_AUTH: neo4j/${NEO4J_PASSWORD:-memorypass}
      NEO4J_PLUGINS: '["apoc"]'
      NEO4J_dbms_security_procedures_unrestricted: apoc.*
      NEO4J_dbms_memory_heap_initial__size: 512m
      NEO4J_dbms_memory_heap_max__size: 2G
    volumes:
      - neo4j-data:/data
      - neo4j-logs:/logs
    restart: unless-stopped
    networks:
      - memory-network

  # Qdrant vector database
  qdrant:
    image: qdrant/qdrant:latest
    container_name: cognitia-qdrant
    ports:
      - "6333:6333"  # HTTP API
      - "6334:6334"  # gRPC
    volumes:
      - qdrant-data:/qdrant/storage
    restart: unless-stopped
    networks:
      - memory-network

  # Redis for Celery
  redis-memory:
    image: redis:7-alpine
    container_name: cognitia-redis-memory
    ports:
      - "6380:6379"
    volumes:
      - redis-memory-data:/data
    restart: unless-stopped
    networks:
      - memory-network

  # Celery Worker for background tasks
  celery-worker:
    build:
      context: ./src/cognitia/memory
      dockerfile: Dockerfile
    container_name: cognitia-celery-worker
    command: celery -A celery_app worker --loglevel=info --concurrency=2
    environment:
      NEO4J_URI: bolt://neo4j:7687
      NEO4J_USER: neo4j
      NEO4J_PASSWORD: ${NEO4J_PASSWORD:-memorypass}
      QDRANT_URL: http://qdrant:6333
      QDRANT_COLLECTION: cognitia_episodes
      OLLAMA_URL: http://172.17.0.1:11434
      OLLAMA_MODEL: llama3.2:latest
      EMBEDDING_MODEL: sentence-transformers/all-MiniLM-L6-v2
      PERSONA_STORAGE_DIR: /app/personas
      REDIS_HOST: redis-memory
      REDIS_PORT: 6379
      OPENAI_API_KEY: ollama-placeholder
    depends_on:
      - neo4j
      - qdrant
      - redis-memory
    volumes:
      - ./personas:/app/personas
    restart: unless-stopped
    networks:
      - memory-network

  # Celery Beat for scheduled tasks
  celery-beat:
    build:
      context: ./src/cognitia/memory
      dockerfile: Dockerfile
    container_name: cognitia-celery-beat
    command: celery -A celery_app beat --loglevel=info
    environment:
      NEO4J_URI: bolt://neo4j:7687
      NEO4J_USER: neo4j
      NEO4J_PASSWORD: ${NEO4J_PASSWORD:-memorypass}
      QDRANT_URL: http://qdrant:6333
      QDRANT_COLLECTION: cognitia_episodes
      OLLAMA_URL: http://172.17.0.1:11434
      OLLAMA_MODEL: llama3.2:latest
      EMBEDDING_MODEL: sentence-transformers/all-MiniLM-L6-v2
      PERSONA_STORAGE_DIR: /app/personas
      REDIS_HOST: redis-memory
      REDIS_PORT: 6379
    depends_on:
      - redis-memory
    restart: unless-stopped
    networks:
      - memory-network

  # Optional: vLLM for optimized inference
  # Uncomment if you want to use vLLM instead of Ollama
  # vllm:
  #   image: vllm/vllm-openai:latest
  #   container_name: cognitia-vllm
  #   runtime: nvidia
  #   ports:
  #     - "8003:8000"
  #   environment:
  #     MODEL_NAME: meta-llama/Llama-3.2-3B-Instruct
  #     TENSOR_PARALLEL_SIZE: 1
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: 1
  #             capabilities: [gpu]
  #   restart: unless-stopped
  #   networks:
  #     - memory-network

volumes:
  neo4j-data:
  neo4j-logs:
  qdrant-data:
  redis-memory-data:

networks:
  memory-network:
    driver: bridge
